# ─────────────────────────────────────────────────────────────────────────────
# AI Crew Studio — Environment Variables
# Copy this file to .env and fill in your values
# ─────────────────────────────────────────────────────────────────────────────

# ── LLM API Keys (at least one required) ─────────────────────────────────────
OPENAI_API_KEY=
ANTHROPIC_API_KEY=
OPENROUTER_API_KEY=

# ── Ollama (for local models) ────────────────────────────────────────────────
# Uncomment the ollama service in compose.yaml to use local models
OLLAMA_BASE_URL=http://ollama:11434

# ── Ports ────────────────────────────────────────────────────────────────────
FRONTEND_PORT=3000
BACKEND_PORT=8080

# ── Config file path (mounted into backend container) ────────────────────────
CONFIG_FILE=./config.yaml

# ── Flask environment ────────────────────────────────────────────────────────
FLASK_ENV=production
