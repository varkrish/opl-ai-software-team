# =============================================================================
# LLM Configuration
# =============================================================================
# Environment: local (uses Ollama) or production (uses cloud providers)
LLM_ENVIRONMENT=local

# -----------------------------------------------------------------------------
# Local LLM (Ollama) - for development/testing
# (Not used when LLM_ENVIRONMENT=production)
# -----------------------------------------------------------------------------
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=mixtral:8x7b

# -----------------------------------------------------------------------------
# Production LLM Models - API Keys
# -----------------------------------------------------------------------------
# Get your keys from:
# - OpenAI: https://platform.openai.com/api-keys
# - Anthropic: https://console.anthropic.com/
# - Google: Use gcloud commands (see CODE_REVIEW_GUIDE.md) or visit:
#   https://makersuite.google.com/app/apikey (if you have access)

OPENAI_API_KEY=
ANTHROPIC_API_KEY=
GOOGLE_API_KEY=
OPENROUTER_API_KEY=

# -----------------------------------------------------------------------------
# Model Selection per Agent Type
# (Used when LLM_ENVIRONMENT=production)
# -----------------------------------------------------------------------------
# Gemini Models Configuration:
# - gemini-1.5-pro: Best quality, $1.25/$5 per 1M tokens (for managers)
# - gemini-1.5-flash: Fast & cheap, $0.075/$0.30 per 1M tokens (for workers)

LLM_MODEL_MANAGER=x-ai/grok-4.1-fast:free
LLM_MODEL_WORKER=x-ai/grok-4.1-fast:free
LLM_MODEL_REVIEWER=x-ai/grok-4.1-fast:free

# =============================================================================
# Budget Settings
# =============================================================================
BUDGET_MAX_COST_PER_PROJECT=100.00
BUDGET_MAX_COST_PER_HOUR=10.00
BUDGET_ALERT_THRESHOLD=0.8

# =============================================================================
# Infrastructure Configuration
# =============================================================================

# -----------------------------------------------------------------------------
# Cache (Dragonfly or Redis-compatible)
# -----------------------------------------------------------------------------
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=

# -----------------------------------------------------------------------------
# RabbitMQ (for future distributed setup)
# -----------------------------------------------------------------------------
RABBITMQ_HOST=localhost
RABBITMQ_PORT=5672
RABBITMQ_USER=guest
RABBITMQ_PASSWORD=guest

# -----------------------------------------------------------------------------
# PostgreSQL (for future distributed setup)
# -----------------------------------------------------------------------------
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=ai_dev_crew
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres

# =============================================================================
# Workspace Configuration

# Git Operations (set to false to skip git init/commit during local testing)
ENABLE_GIT=false

# =============================================================================
WORKSPACE_PATH=./workspace
GIT_REPO_URL=

# =============================================================================
# Logging & Project Settings

# Retry Configuration
MAX_RETRY_ATTEMPTS=100

# =============================================================================
LOG_LEVEL=INFO
PROJECT_ID=default-project

# =============================================================================
# Notes
# =============================================================================
# To get your Google API key:
# 1. Run: gcloud auth login
# 2. Run: gcloud services enable generativelanguage.googleapis.com
# 3. Create API key using gcloud commands (see documentation)
# 4. Paste the key above in GOOGLE_API_KEY=
